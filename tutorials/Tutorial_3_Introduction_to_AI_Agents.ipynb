{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tutorial 3** - Introduction to AI Agents\n",
    "\n",
    "After getting to know the data, it's time to build our first generative AI solution. The skills you will learn here will have a tremendous impact.\n",
    "\n",
    "Before we dive into building our first GenAI solution, let's take a moment to understand what we're working with and why it's so exciting.\n",
    "\n",
    "### What is Generative AI?\n",
    "Generative AI refers to artificial intelligence systems that can create new content, ideas, or solutions. Unlike traditional AI that primarily analyzes existing data, GenAI can produce original text, images, code, or even music. The most common type of GenAI you might have heard of is Large Language Models (LLMs) like ChatGPT or Claude, which can generate human-like text based on the input they receive.\n",
    "\n",
    "### Why AI Agents?\n",
    "AI agents take GenAI a step further. An AI agent is like a virtual assistant with a specific role, expertise, and set of goals. It can use GenAI capabilities (like language models) to perform tasks, make decisions, and interact with humans or other AI agents.\n",
    "Learning about AI agents is valuable for your future work and projects because:\n",
    "\n",
    "- Automation of Complex Tasks: AI agents can handle intricate, multi-step processes that previously required human intervention.\n",
    "- Enhanced Problem-Solving: By combining different AI agents with various expertise, you can tackle complex problems more efficiently.\n",
    "- Personalized Experiences: AI agents can adapt to individual user needs, creating more tailored solutions in fields like customer service, education, or healthcare.\n",
    "- Improved Decision-Making: In business and research, AI agents can process vast amounts of data to provide insights and recommendations.\n",
    "- Future-Proofing Your Skills: As AI continues to evolve, understanding how to work with and develop AI agents will be a crucial skill in our industry.\n",
    "\n",
    "In this tutorial, you'll learn how to build a *multi-agent system* using AWS Bedrock and [CrewAI](https://docs.crewai.com/). This hands-on experience will give you a strong foundation in working with AI agents, setting you up for success in this rapidly evolving field.\n",
    "\n",
    "Let's get started by exploring the basics of AI agents and then move on to creating our own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. [What are AI agents](#what-are-ai-agents)\n",
    "   - Definition and characteristics of AI agents\n",
    "   - How AI agents differ from traditional GenAI\n",
    "\n",
    "2. [Hello GenAI World](#hello-genai-world)\n",
    "   - Using Large Language Models with Amazon Bedrock\n",
    "   - Setting up and using the Bedrock API\n",
    "\n",
    "3. [Building Our First AI Agent](#building-our-first-ai-agent)\n",
    "   - Step-by-step guide to creating a simple code assistant\n",
    "   - Hands-on exercises and code examples\n",
    "\n",
    "4. [Creating a first solution](#creating-a-first-solution)\n",
    "    - Build a agentic system that can answer questions about the PIRLS dataset\n",
    "\n",
    "5. [Conclusion](#conclusion)\n",
    "   - Summary of key learnings and a preview of tutorial 4!\n",
    "\n",
    "6. [Appendix](#appendix)\n",
    "    - Main CrewAI concepts in detail\n",
    "    - Working locally with AWS credentials\n",
    "    - Other frameworks for building agentic systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are AI Agents? <a id='what-are-ai-agents'></a>\n",
    "\n",
    "AI agents are like smart digital assistants with specific roles and goals. They use large language models (LLMs), to perform tasks, make decisions, and solve problems. Unlike simple chatbots or traditional AI systems that follow fixed rules, AI agents can adapt, learn, and work together to tackle complex challenges.\n",
    "\n",
    "Let's break down the key components of an AI agent system:\n",
    "\n",
    "1. **Agents**: These are the core \"actors\" in our system. Each agent has:\n",
    "   - A specific role (e.g., \"Python Developer\" or \"Code Tester\")\n",
    "   - A set of skills or expertise\n",
    "   - Goals to achieve\n",
    "   - The ability to use tools and make decisions\n",
    "\n",
    "\n",
    "2. **Tools**: These are functions or capabilities that agents can use to perform tasks. Tools might include:\n",
    "   - Code execution engines\n",
    "   - Database query functions\n",
    "   - Web search capabilities\n",
    "   - Mathematical calculations\n",
    "\n",
    "3. **Tasks**: These are the specific jobs or objectives assigned to agents. A task typically includes:\n",
    "   - A clear description of what needs to be done\n",
    "   - The expected output or result\n",
    "   - Any constraints or special instructions\n",
    "\n",
    "4. **Crew**: This is a group of agents working together to achieve a common goal. The crew concept allows for:\n",
    "   - Division of labor based on agent specialties\n",
    "   - Collaboration and information sharing between agents\n",
    "   - Coordinated problem-solving approaches\n",
    "\n",
    "AI agents differ from traditional LLMs in several ways:\n",
    "- They have specific roles and goals, rather than being general-purpose language processors\n",
    "- They can use external tools and resources to augment their capabilities\n",
    "- They can work together in teams (crews) to solve complex problems\n",
    "- They maintain context and can engage in multi-step problem-solving processes\n",
    "\n",
    "This system allows for powerful, flexible problem-solving capabilities that go beyond what a single AI model can achieve on its own.\n",
    "\n",
    "There are plenty of good resources on the topic, e.g. the [LangChain Blog](https://blog.langchain.dev/langgraph-multi-agent-workflows/) or the official [CrewAI course](https://learn.crewai.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello GenAI World <a id='hello-genai-world'></a>\n",
    "\n",
    "Before we dive into building complex AI agent systems, we need to start with the foundation: accessing and interacting with a Large Language Model (LLM). LLMs are the powerhouse behind our AI agents, providing the language understanding and generation capabilities that make our agents intelligent and versatile.\n",
    "\n",
    "### Why Start with an LLM?\n",
    "\n",
    "1. **Foundation of Intelligence**: LLMs form the cognitive core of our AI agents. They provide the language processing capabilities that allow agents to understand tasks, generate responses, and make decisions.\n",
    "\n",
    "2. **Flexibility**: By starting with a raw LLM, we can understand its capabilities and limitations. This knowledge is crucial when we start designing our agents and their specific roles.\n",
    "\n",
    "3. **Customization**: Understanding how to interact with an LLM directly gives us the flexibility to customize our agents' behaviors and responses in the future.\n",
    "\n",
    "4. **Scalability**: As we build more complex systems, knowing how to efficiently interact with the LLM will be key to creating scalable solutions.\n",
    "\n",
    "For this tutorial, we'll be using Amazon Bedrock, which provides access to various powerful LLMs. We'll specifically use the Claude 3 Haiku model. It's a great and cheap baseline model. Later you might want to add stronger models like Claude 3.5 Sonnet for more complex tasks.  The [Chatbot Arena](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) is a great overview of the latest models and their respective strenghts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Amazon Bedrock\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our connection to Amazon Bedrock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure all required packages are installed. This may take a bit\n",
    "# Note the -q flag in the end. It blocks the output. If you want to see what's going on, remove it\n",
    "!pip install crewai langchain-aws -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "assert dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "# Set up the model ID for Claude\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "#MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Initialize the ChatBedrock instance\n",
    "llm = ChatBedrock(model_id=MODEL_ID, model_kwargs={'temperature': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setup:\n",
    "\n",
    "- We're using the `ChatBedrock` class from the `langchain_aws` library, which provides a convenient interface to interact with Bedrock models.\n",
    "- We specify the model ID for Claude 3 Haiku, a powerful and efficient model suitable for our learning purposes. You can check model IDs [here](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/models).\n",
    "- We set the `temperature` parameter to 0, which makes the model's outputs more deterministic and focused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your First Interaction with the LLM\n",
    "Now that we have our LLM set up, let's try a simple interaction to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = [\n",
    "    (\"system\", \"You are a helpful assistant that translates English to French.\"),\n",
    "    (\"human\", \"Translate the following sentence: 'Hello, world!'\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly translated \"Hello World!\" to \"Bonour, monde\". You can also see some more info on how many token the request used. More token means more [costs](https://aws.amazon.com/bedrock/pricing/). Prompt Engineering is the skill of writing instructions that get the desired output in as few prompts as possible. The [Prompt Engineering guide](https://www.promptingguide.ai/) is a great way to learn more about it.\n",
    "\n",
    "This simple example demonstrates:\n",
    "\n",
    "- How to set a system message to define the LLM's role\n",
    "- How to send a user message to the LLM\n",
    "- How to receive and display the LLM's response\n",
    "\n",
    "Understanding this basic interaction is crucial as we move forward to build more complex AI agent systems. In the next sections, we'll expand on this foundation to create agents with specific roles, tasks, and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our First AI Agent\n",
    "\n",
    "Now that we understand the basics of AI agents and have interacted with an LLM, let's build our first multi-agent system using [CrewAI](https://www.crewai.com/). We'll create a Python Help Crew that can assist with Python programming tasks. (Note that you can also use it during developing your solution!)\n",
    "\n",
    "## What Our Crew Will Do\n",
    "\n",
    "Our Python Help Crew will consist of two AI agents working together:\n",
    "\n",
    "1. A Python Developer agent that writes code based on user requests.\n",
    "2. A Tester agent that evaluates and tests the code produced by the Python Developer.\n",
    "\n",
    "This crew will be able to:\n",
    "- Understand user requests for Python-related tasks\n",
    "- Generate Python code to solve those tasks\n",
    "- Test the generated code for correctness\n",
    "- Iterate on the solution if needed\n",
    "\n",
    "This setup demonstrates how multiple AI agents can collaborate to produce more reliable and tested code than a single agent could on its own.\n",
    "\n",
    "Let's break down the implementation of our Python Help Crew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.project import agent, crew, task\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PythonHelpCrew:\n",
    "    def __init__(self, llm: ChatBedrock) -> None:\n",
    "        self.llm = llm\n",
    "\n",
    "    def run(self, prompt: str) -> str:\n",
    "        self.prompt = prompt\n",
    "        return self.crew().kickoff().raw\n",
    "\n",
    "    @agent\n",
    "    def pythonDeveloper(self) -> Agent:\n",
    "        return Agent(\n",
    "            role=\"Python developer\", \n",
    "            backstory=\"Experienced Python developer with deep knowledge in Python programming.\", # We do a role assumption technique here\n",
    "            goal=\"Write a Python code to solve the user's question.\", # The simpler goal the better\n",
    "            llm=self.llm,\n",
    "            allow_delegation=False,\n",
    "            verbose=True)\n",
    "\n",
    "    @agent\n",
    "    def tester(self) -> Agent:\n",
    "        return Agent(\n",
    "            role=\"Tester\",\n",
    "            backstory=\"Experienced tester with deep knowledge in testing and using provided tools.\", # We do a role assumption technique here and order the agent to provided tool for testing.\n",
    "            goal=\"Test the Python code to ensure it works correctly. Only if you are sure that there is an issue with the code, send it back to the Python developer.\", # The simpler goal the better\n",
    "            llm=self.llm,\n",
    "            allow_delegation=True, # Allow delegation to other agents (python developer), if code fails it will be sent back to the python developer to fix.\n",
    "            tools = [eval_python_code], # Tools need to be passed in python list format, even if there is only one tool.\n",
    "            verbose=True)\n",
    "\n",
    "\n",
    "    @task\n",
    "    def code_python_task(self) -> Task: \n",
    "        return Task(\n",
    "            description=f\"Write a python code to solve the user's question: {self.prompt}.\", # We format task description with the user prompt passed in the run method.\n",
    "            expected_output=\"Python code that solves the user's question. Only return Python code. NO additional explanations.\", # We specify the expected output of the task. Note that we narrow down response distribution to python code only.\n",
    "            agent=self.pythonDeveloper()) # Pass appropriate agent to the task.\n",
    "    @task\n",
    "    def test_code_task(self) -> Task:\n",
    "        return Task(\n",
    "            description=\"Test the python code to ensure it works correctly.\",\n",
    "            expected_output=\"Only the tested Python code. NO additional explanations.\",\n",
    "            agent=self.tester())\n",
    "\n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        return Crew(\n",
    "            agents=self.agents,  # List of agents participating in the crew. Each agent flagged with @agent decorator will be added here.\n",
    "            tasks=self.tasks,  # List of tasks to be performed by the agents in the crew. Each task flagged with @task decorator will be added here.\n",
    "            process=Process.sequential,  # Process type (sequential or hierarchical)\n",
    "            verbose=True,  # True if you want to see the detailed outputs\n",
    "            max_iter=5,  # Maximum number of repetitions each agent can perform to get the generate the best answer.\n",
    "            cache=False  # Caching option. Useful when tools produce large output like result of SQL queries.\n",
    "        )\n",
    "\n",
    "\n",
    "@tool\n",
    "def eval_python_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Evaluate the given Python code and return the result.\n",
    "\n",
    "    Parameters:\n",
    "    code (str): The Python code to be executed.\n",
    "\n",
    "    Returns:\n",
    "    str: The result of executing the code. If the code executes successfully, it returns \"Code executed successfully.\"\n",
    "         If an exception occurs during execution, it returns the error message as a string.\n",
    "    \"\"\"\n",
    "    # Remember each tool should have informative docstring. It will be used in the CrewAI platform to provide information about the tool.\n",
    "    # We recommend generating it with GenAI tools such as Microsoft Copilot.\n",
    "    import sys\n",
    "    import io\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    redirected_output = sys.stdout = io.StringIO()\n",
    "    try:\n",
    "        exec(code, {})\n",
    "        result = redirected_output.getvalue()\n",
    "        return result if result else \"Code executed successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during execution: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the key components of our PythonHelpCrew:\n",
    "\n",
    "1. Agents:\n",
    "    - `pythonDeveloper`: Responsible for writing Python code based on the user's request.\n",
    "    - `tester`: Tasked with testing the code produced by the Python developer.\n",
    "\n",
    "\n",
    "2. Tasks:\n",
    "    - `code_python_task`: Assigns the coding task to the Python developer agent.\n",
    "    - `test_code_task`: Assigns the testing task to the tester agent.\n",
    "\n",
    "3. Crew:\n",
    "    - Assembles the agents and tasks, defining how they work together.\n",
    "\n",
    "4. Tool:\n",
    "    - `eval_python_code`: A function that executes Python code and returns the result or any errors.\n",
    "\n",
    "The `@agent`, `@task`, and `@crew` decorators are used to automatically add these components to our crew. This approach simplifies the creation and management of our multi-agent system.\n",
    "Now, let's test our Python Help Crew with a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pythonCrew = PythonHelpCrew(llm=llm)\n",
    "\n",
    "print(pythonCrew.run(\"Write a function to get the n-th Fibonacci number.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows us the step-by-step process of our AI agents working together:\n",
    "\n",
    "1. Python Developer Agent:\n",
    "    - The agent receives the task to write a function for the n-th Fibonacci number.\n",
    "    - It generates a Python function that recursively calculates Fibonacci numbers.\n",
    "\n",
    "2. Tester Agent:\n",
    "    - The tester receives the code from the Python Developer.\n",
    "    - It uses the eval_python_code tool to test the function with various inputs.\n",
    "    - The agent verifies that the output matches the expected Fibonacci sequence.\n",
    "\n",
    "3. Final Output:\n",
    "    - The tested and verified function is returned as the final result.\n",
    "\n",
    "This process demonstrates how our multi-agent system collaborates to produce a working solution. The Python Developer creates the code, and the Tester ensures its correctness, providing a more robust result than a single agent could achieve alone.\n",
    "\n",
    "While the example is a good introduction you'll want to take a look a the [documentation](https://docs.crewai.com/core-concepts/Agents/) to understand all the details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises:**\n",
    "- Add an additional agent & task that optimizes the code to the above example.\n",
    "- The examples uses a sequential workflow where one task after the other is process. CrewAI also supports a more complex [hierarchical workflow]((https://docs.crewai.com/how-to/Hierarchical/#implementing-the-hierarchical-process)) where one agent delegates tasks as necessary. Try it out.\n",
    "- There are plenty of other examples the [crewAI-examples repository](https://github.com/crewAIInc/crewAI-examples). Try adding a new tool to the above example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging AI Agents\n",
    "Debugging AI agents can be challenging due to their complex, often non-deterministic nature. Here are some strategies to help you troubleshoot your agent-based systems:\n",
    "\n",
    "- Enable Verbose Output: Always start with verbose mode enabled. This provides detailed logs of agent interactions, decision-making processes, and tool usage.\n",
    "- Isolate Components: If you're facing issues, try testing individual agents or tools in isolation. This can help pinpoint where the problem is occurring. (This is a good practice in every domain!)\n",
    "- Use Print Statements/Logging: Don't underestimate the power of strategic print statements. They can help you track the flow of information and decision-making within your agents.\n",
    "- Test with Simple Inputs: Start with very simple, predictable inputs when testing new features or debugging issues. Gradually increase complexity as you verify each component is working correctly.\n",
    "- Analyze Tool Usage: Pay close attention to how agents are using tools. Incorrect tool usage is a common source of errors in agent systems.\n",
    "- Check Model Outputs: Sometimes, issues stem from unexpected or low-quality outputs from the underlying language model. Always verify that the model is producing sensible responses. Small changes in the prompt can have a big impact on the quality\n",
    "- **Use AI to Debug AI**: Interestingly, you can leverage LLMs themselves to help debug your agent system. Try describing the issue you're facing to an LLM (like the one you're using in your agents) and ask for potential causes or solutions. LLMs can often provide insightful suggestions or help you see the problem from a different perspective.\n",
    "\n",
    "Remember, debugging AI agents is often an iterative process. Be patient, methodical, and don't hesitate to revisit your agent designs if you're consistently running into issues. With practice, you'll develop a strong intuition for how these systems work and how to efficiently troubleshoot them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a first solution\n",
    "\n",
    "The goal of the GDSC is to create an AI system that can answer education related questions utilizing the PIRLS 2021 dataset that was described in tutorial 2.\n",
    "You can find example questions on the [arena page](https://gdsc.ce.capgemini.com/app/arena/) and even submit your own question if you'd like to add some.\n",
    "\n",
    "Let's start by looking at some of the questions:\n",
    "- \"How many countries reported that at least 85% of their students reached the Low International Benchmark?\"\n",
    "\n",
    "This question implicitly refers to the PIRLS dataset. Our solution will need to infer this, access the database and execute the right query to find the correct answer.\n",
    "\n",
    "- \"What are the main reasons kids in Germany might not be doing so well in reading, and do you have any ideas on how to help them get better?\"\n",
    "\n",
    "The answers from the PIRLS study can provide valueable insights here, but you'll probably need to include general world knowledge for the final answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'll need:\n",
    "- An *agent* that writes and executes database queries\n",
    "- A *tool* for accessing the PRILS database\n",
    "\n",
    "With this in mind, here is a first draft. We start with the tool that connects to the PIRLS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "DB_ENDPOINT = 'gdsc-2024-public-uesco-cluster-instance-1.crqaeg62obh7.us-east-1.rds.amazonaws.com'\n",
    "DB_PORT = '5432'\n",
    "DB_USER = 'INSERT_USER'\n",
    "DB_PASSWORD ='INSERT_PASSWORD'\n",
    "DB_NAME ='postgres'\n",
    "\n",
    "connection_string = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_ENDPOINT}:{DB_PORT}/{DB_NAME}'\n",
    "db_engine = sqlalchemy.create_engine(connection_string)\n",
    "\n",
    "@tool\n",
    "def query_database(query: str) -> str:\n",
    "    \"\"\"Query the PIRLS postgres database and return the results as a string.\n",
    "\n",
    "    Args:\n",
    "        query (str): The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        str: The results of the query as a string, where each row is separated by a newline.\n",
    "    \"\"\"    \n",
    "    with db_engine.connect() as connection:\n",
    "        try:\n",
    "            res = connection.execute(sqlalchemy.text(query))\n",
    "        except Exception as e:\n",
    "            return f'Encountered exception {e}.'\n",
    "    ret = '\\n'.join(\", \".join(map(str, result)) for result in res)\n",
    "    return f'Query: {query}\\nResult: {ret}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in [tutorial 2](https://github.com/cg-gdsc/GDSC-7/blob/main/tutorials/Tutorial_2_Data_Understanding.ipynb), we create a connection to the database. Our custom tool takes SQL queries and executes them against the database.\n",
    "\n",
    "Next, we create one agent that has basic knowledge of the database and access to our new tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # Make sure Python finds our custom files\n",
    "from textwrap import dedent\n",
    "\n",
    "# We use our custom \"Submission\" class. It forces the object to have a .run function. We'll use this in the evaluation. \n",
    "# It allows you to work with ANY framework as long as you provide us with an object of the \"Submission\" class.\n",
    "from src.static.submission import Submission  \n",
    "\n",
    "class BasicPIRLSCrew(Submission):\n",
    "    \n",
    "    def __init__(self, llm: ChatBedrock):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def run(self, prompt: str) -> str:\n",
    "        return self.crew().kickoff(inputs={\"prompt\": prompt}).raw    \n",
    "    \n",
    "    @agent\n",
    "    def database_expert(self) -> Agent:\n",
    "        return Agent(\n",
    "            role=\"PIRLS Student Database Expert\",\n",
    "            backstory=dedent(\"\"\"\n",
    "                You are a senior data engineer that has a lot of experience in working with the PIRLS data.\n",
    "                Given a question, you come up with an SQL query that get the relevant data and run it with the'query_database' tool.\n",
    "                \n",
    "                You know that there is the table 'Students' with columns Student_ID and Country_ID, and a table 'Countries' with columns 'Country_ID', 'Name' and 'Code'.\n",
    "            \"\"\"),\n",
    "            goal=\"Use the tool to query the database and answer the question.\",\n",
    "            llm=self.llm,\n",
    "            allow_delegation=False,\n",
    "            verbose=True,\n",
    "            tools=[query_database]\n",
    "        )\n",
    "    \n",
    "    @task\n",
    "    def answer_question(self) -> Task:\n",
    "        return Task(\n",
    "            description=\"Query the database and answer the question \\\"{prompt}\\\".\",\n",
    "            expected_output=\"Answer to the queston\",\n",
    "            agent=self.database_expert()\n",
    "        )\n",
    "\n",
    "   \n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        return Crew(\n",
    "            agents=self.agents,\n",
    "            tasks=self.tasks,\n",
    "            process=Process.sequential,\n",
    "            verbose=True,\n",
    "            max_iter=3,\n",
    "            cache=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = BasicPIRLSCrew(llm=llm)\n",
    "\n",
    "print(crew.run(\"How many students participated in PIRLS 2021.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it works! :)\n",
    "\n",
    "**Exercises:**\n",
    "- Test the `BasicPIRLSCrew` with the more complex questions mentioned in the beginning of the section.\n",
    "- You'll find that the `BasicPIRLSCrew` cannot answer harder questions. How could you improve it?\n",
    "- Change the backstory of the Agent. What's the effect on the answers you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this tutorial, we've taken our first steps into the world of AI agents and multi-agent systems. We've learned:\n",
    "\n",
    "- What AI agents are and how they differ from traditional LLMs\n",
    "- How to use Amazon Bedrock to access powerful language models\n",
    "- The basics of the CrewAI framework, including agents, tasks, crews, and tools\n",
    "- How to build and test a simple AI agent for code assistance\n",
    "- How to build a basic solution for the GDSC task that will serve as our first submission\n",
    "\n",
    "This foundation will be crucial as we move forward in our GenAI journey. In the [next tutorial](https://github.com/cg-gdsc/GDSC-7/blob/main/tutorials/Tutorial_4_Submitting_Your_Solution.ipynb), we'll submit our first basic solution. And in [tutorial 5](https://github.com/cg-gdsc/GDSC-7/blob/main/tutorials/Tutorial_5_Advanced_AI_Agents.ipynb) we'll learn how to improve the `BasicPIRLSCrew` so that it can answer all basic questions.\n",
    "\n",
    "Remember, the field of AI is rapidly evolving. The skills you've learned today are just the beginning. Continue to experiment, learn, and stay curious about new developments in this exciting field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main CrewAI concepts\n",
    "\n",
    "#### Agents\n",
    "\n",
    "Agent arguments are used to define the characteristics and behavior of an agent in the Crew AI framework. \n",
    "\n",
    "For the `python_developer` agent, the following arguments are defined:\n",
    "- `role`: Specifies the role of the agent, which is \"Python developer\" in this case.\n",
    "- `backstory`: Provides a description of the agent's background and expertise. It states that the agent is an experienced Python developer with deep knowledge in Python programming.\n",
    "- `goal`: Defines the agent's goal, which is to write a Python code to solve the user's question.\n",
    "- `llm`: Specifies the language model to be used by the agent, which is an instance of the `ChatBedrock` class.\n",
    "- `allow_delegation`: Determines whether the agent can delegate tasks to other agents. In this case, delegation is not allowed.\n",
    "- `verbose`: Controls the verbosity level of the agent's output. It is set to `True` to enable verbose output.\n",
    "\n",
    "For the `tester` agent, the following arguments are defined:\n",
    "- `role`: Specifies the role of the agent, which is \"tester\".\n",
    "- `backstory`: In this case the agent is an experienced tester with deep knowledge in testing.\n",
    "- `goal`: Test the Python code to ensure it works correctly.\n",
    "- `llm`: `ChatBedrock` class.\n",
    "- `allow_delegation`: In this case, delegation is allowed. If the code does not pass the test, it will be re-delegated back to the Python developer agent.\n",
    "- `tools`: Specifies the tools that the agent can use. Agent can use tool if provided but doesn't have to, its up to his decision unless we explicitly order him to do so in `goal` or `backstory` In this case, the `eval_python_code` function is defined as a tool for the tester agent.\n",
    "- `verbose`: It is set to `True` to enable verbose output.\n",
    "\n",
    "\n",
    "You can check other agent attributes that may come useful [here](https://docs.crewai.com/core-concepts/Agents/).\n",
    "#### Tasks\n",
    "\n",
    "Tasks can be defined as the steps an ai crew must take to accomplish a common goal. As LHMs (Large Human Models), we can recognize what steps must be taken in order for the task we define to be accomplished in the best possible way.\n",
    "Our example ai crew specializes in writing code for python, so what steps must be taken to write code for python?  Write code to python and test it.\n",
    "\n",
    "For the `code_python_task` task, the following arguments are defined:\n",
    "- `description` : Short description of the task, for this task it is to write a python code. It also contains original task queried by user.\n",
    "- `expected_output` : Short description of expected output, here we can stabilize output to our expected form. For this task we want Python code that solves the task, python code only.\n",
    "- `agent` : Here we forward our previously defined `python_developer` agent.\n",
    "\n",
    "For the `test_code_task` task, the following arguments are defined:\n",
    "- `description` : For this task we want our agent to test the code produced by `python_developer` agent.\n",
    "- `expected_output` : In this case results of testing.\n",
    "- `agent` : Here we forward our previously defined `tester` agent.\n",
    "\n",
    "You can check other task attributes that may come useful [here](https://docs.crewai.com/core-concepts/Tasks/).\n",
    "#### Crew\n",
    "\n",
    "In crew function we put all building blocks together and assemble our crew.\n",
    "- `agents` : Here we pass our agents, in this implementation framework automatically recognizes agent marked by `@agent` flag, using this flag adds object to global list of agents.\n",
    "- `tasks` : Similarly to agents, framework recognizes tasks marked by `@task` flag.\n",
    "- `process` : Here we define inference process. In our example we use `Process.sequential` where crew starts from task specified by us, in our example we defined `code_python_task` first so it will start from it. Another approach implemented by Crew AI framework is `Process.hierarchical`, you can read more about it here [Hierarchical Process](https://docs.crewai.com/how-to/Hierarchical/#implementing-the-hierarchical-process).\n",
    "- `verbose` : Here we define verbosity for crew output.\n",
    "- `max_iter` : Here we define number of repetitions each agent can take in solving task. Changing this value has a great impact on balance between thoroughness and efficiency. Once the agent approaches this number, it will try its best to give a good answer.\n",
    "- `cache` : This argument specifies if crew will use cache to store output from tools. For example if tool produces large output like result of SQL queries, storing it in cache reduces load on external resources and speeds up the execution time.\n",
    "\n",
    "You can check other crew attributes that may come useful [here](https://docs.crewai.com/core-concepts/Crews/).\n",
    "#### Tools\n",
    "\n",
    "Tools are python functions that can be used by AI agents. They can perform a whole range of actions such as in this case executing python code, serving as a calculator or connecting to a database. These functions need to have a docstring so that agents can parse what input and output the function takes. These tools can be very general as in this case, or be directed to perform a strongly determined action such as executing a single SQL query. \n",
    "\n",
    "In this implementation we mark our `eval_python_code` function with `@tool` flag to add it to tools list.\n",
    "\n",
    "You can read more on crewAI tools [here](https://docs.crewai.com/core-concepts/Tools/#key-characteristics-of-tools).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working locally\n",
    "If you aren't working in Sagemaker, you need to set the following environment variables before running the above code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Setup environmental variables, for local IDE users only\n",
    "# import os\n",
    "# os.environ['AWS_ACCESS_KEY_ID'] = 'your_access_key_id'\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY'] = 'your_secret_access_key'\n",
    "# os.environ['AWS_SESSION_TOKEN'] = 'your_session_token'\n",
    "# os.environ['AWS_REGION'] = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find them in the AWS access portal under `Access keys`\n",
    "\n",
    "![title](../images/t1_aws_acc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativly, you can of course also use an .env file or anything similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other frameworks for building agentic systems\n",
    "\n",
    "When diving into the world of AI agents, you'll encounter various frameworks, each with its own strengths and complexities. [CrewAI](https://docs.crewai.com/), which we've used in this tutorial, stands out as an excellent choice for beginners and those looking to quickly prototype multi-agent systems.\n",
    "\n",
    "CrewAI's primary advantage is its simplicity and intuitive design. It allows you to define agents, tasks, and workflows with minimal boilerplate code, making it easy to get your first AI agent up and running quickly. The framework's focus on the \"crew\" concept provides a natural way to think about and structure multi-agent interactions, which can be particularly helpful when you're just starting out.\n",
    "\n",
    "In contrast, frameworks like [LangChain](https://www.langchain.com/) and its extension [LangGraph](https://www.langchain.com/langgraph) offer more advanced features and greater flexibility. LangChain provides a comprehensive set of tools for building applications with LLMs, including sophisticated prompt management, memory systems, and a wide array of integrations. LangGraph builds on this to offer complex multi-agent orchestration and workflow management.\n",
    "\n",
    "While these frameworks are incredibly powerful, they come with a steeper learning curve. They're better suited for more complex projects or when you need fine-grained control over every aspect of your AI system. As you grow more comfortable with AI agent concepts and start tackling more challenging problems, exploring these frameworks can open up new possibilities.\n",
    "\n",
    "For now, CrewAI's balance of simplicity and capability makes it an ideal starting point. It allows you to grasp the fundamental concepts of AI agents without getting bogged down in excessive complexity. As you progress in your AI journey, you'll be well-prepared to explore more advanced frameworks, building on the solid foundation you've established with CrewAI. Note that if you want to use crewAI in a production environment you want to disable the telemetry!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
